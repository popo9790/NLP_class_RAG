{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54be6c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEMINI_API_KEY=\"AIzaSyByqQgBxfkc5jJP5VnmrNNFTeyDRhzdOMo\"\n",
    "# GEMINI_API_KEY=\"AIzaSyAco7s98V4xkciBTSBjZwqcbapJK7cvkw8\"\n",
    "GEMINI_API_KEY=\"AIzaSyAaxYpJWfwqswFZ6ucT6n3u_a5RtNupmvc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7ee77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai.types import Schema, Type, GenerateContentConfig\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# response = client.models.generate_content(\n",
    "#     model=\"gemini-2.5-flash\",\n",
    "#     contents=\"Explain how AI works in a few words\",\n",
    "# )\n",
    "\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e49d29e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is the name of the benchmark suite presented in a recent paper for measuring inference energy consumption?',\n",
       "  'answer': 'The ML.ENERGY Benchmark',\n",
       "  'answer_value': 'ML.ENERGY Benchmark',\n",
       "  'answer_unit': 'is_blank',\n",
       "  'supporting_materials': 'We present the ML.ENERGY Benchmark, a benchmark suite and tool for measuring inference energy consumption under realistic service environments...',\n",
       "  'explanation': 'Quote'},\n",
       " {'question': 'What were the net CO2e emissions from training the GShard-600B model?',\n",
       "  'answer': '4.3 tCO2e',\n",
       "  'answer_value': '4.3',\n",
       "  'answer_unit': 'tCO2e',\n",
       "  'supporting_materials': '\"Training GShard-600B used 24 MWh and produced 4.3 net tCO 2 e.\"',\n",
       "  'explanation': 'Quote'},\n",
       " {'question': 'What is the model size in gigabytes (GB) for the LLaMA-33B model?',\n",
       "  'answer': '64.7 GB',\n",
       "  'answer_value': '64.7',\n",
       "  'answer_unit': 'GB',\n",
       "  'supporting_materials': 'Table 3: Large language models used for evaluation.',\n",
       "  'explanation': 'Table 3'},\n",
       " {'question': 'What was the total electricity consumption of all Google Cloud TPU pods worldwide in 2023, in megawatt-hours?',\n",
       "  'answer': 'Unable to answer with confidence based on the provided documents.',\n",
       "  'answer_value': 'is_blank',\n",
       "  'answer_unit': 'MWh',\n",
       "  'supporting_materials': 'is_blank',\n",
       "  'explanation': 'is_blank'},\n",
       " {'question': 'True or False: Hyperscale data centers in 2020 achieved more than 40% higher efficiency compared to traditional data centers.',\n",
       "  'answer': 'TRUE',\n",
       "  'answer_value': '1',\n",
       "  'answer_unit': 'is_blank',\n",
       "  'supporting_materials': 'Wu 2021, body text near Fig. 1: \"…between traditional and highly optimized hyperscale data centers, power usage effectiveness (PUE) has a stark difference - **more than 40% higher efficiency** for hyperscale data centers (Figure 1).\" Patterson 2021 (p.3): \"…In 2020, [US average PUE] was **1.59**… The PUE for the Iowa datacenter… is **1.11**.\"',\n",
       "  'explanation': 'The >40% statement is explicit in Wu. Patterson\\'s PUE numbers (1.59 vs 1.11) provide a numeric example consistent with \"more than 40% higher efficiency.\"'},\n",
       " {'question': \"For every medium-length GPT-3 completion (prompt= 800 words; response 150 - 300 words), roughly how many 500 mL bottles of water does the model 'drink'?\",\n",
       "  'answer': '0.02 to 0.1 bottles',\n",
       "  'answer_value': '[0.02,0.1]',\n",
       "  'answer_unit': '500 mL bottles',\n",
       "  'supporting_materials': '\"Additionally, GPT-3 needs to -drink- (i.e., consume) a 500ml bottle of water for roughly 10 - 50 medium-length responses, depending on when and where it is deployed.\", \"More specifically, we consider a medium-sized request, each with approximately=800 words of input and 150 - 300 words of output [30]. \"',\n",
       "  'explanation': 'The paper states that one 500ml bottle is consumed for every 10 to 50 responses. Therefore, one response consumes 1/50 to 1/10 of a bottle, which is 0.02 to 0.1 bottles.'},\n",
       " {'question': 'From a sample of 60 papers from top AI conferences, what is the difference between the percentage of CVPR papers that target accuracy and the percentage of CVPR papers that target efficiency?',\n",
       "  'answer': '55%',\n",
       "  'answer_value': '55',\n",
       "  'answer_unit': 'percent',\n",
       "  'supporting_materials': '\"A large majority of the papers target accuracy (90% of ACL papers, 80% of NeurIPS papers and 75% of CVPR papers). Moreover, for both empirical AI conferences (ACL and CVPR) only a small portion (10% and 20% respectively) argue for a new efficiency result.\"',\n",
       "  'explanation': 'Requires calculation (75-20)'},\n",
       " {'question': 'True or False: The AI Act makes energy consumption data from providers publicly available to NGOs, analysts, and the general public.',\n",
       "  'answer': 'FALSE',\n",
       "  'answer_value': '0',\n",
       "  'answer_unit': 'is_blank',\n",
       "  'supporting_materials': \"Section 4.3 Transparency: 'Where the Act does mandate disclosure... this information is restricted to authorities and is not accessible to downstream providers... or the general public.'\",\n",
       "  'explanation': 'Quote'},\n",
       " {'question': 'What is the projected maximum batch size (in samples) for fine-tuning a Mixtral model with a projected GPU capacity of 100?',\n",
       "  'answer': '28 samples per batch',\n",
       "  'answer_value': '28',\n",
       "  'answer_unit': 'samples',\n",
       "  'supporting_materials': 'Figure 13',\n",
       "  'explanation': 'Figure'},\n",
       " {'question': 'What was the approximate speedup in inference throughput for LLaMA-7B when using NVIDIA A100 GPUs compared to V100 GPUs?',\n",
       "  'answer': '2x',\n",
       "  'answer_value': '2',\n",
       "  'answer_unit': 'multiplier',\n",
       "  'supporting_materials': '\"anywhere from a 2 times (7B) … increase … on the A100 when compared to the V100\"',\n",
       "  'explanation': 'Quote'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "example_output_df = pd.read_csv(\"train_QA.csv\")\n",
    "example_output_df = example_output_df[[\"question\", \"answer\", \"answer_value\", \"answer_unit\", \"supporting_materials\", \"explanation\"]]\n",
    "example_output_df.head()\n",
    "example_outputs = example_output_df.to_dict(orient=\"records\")\n",
    "example_outputs = example_outputs[:10]  # 只保留前 5 筆資料以節省資源\n",
    "example_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcc46c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What was the average increase in U.S. data center electricity consumption between 2010 and 2014?',\n",
       "  'answer_unit': 'percent'},\n",
       " {'question': 'In 2023, what was the estimated amount of cars that could be taken off the road equivalent to the amount of metric tons of CO2e the Amazon Solar Farm Maryland-CPV Backbone would avoid?',\n",
       "  'answer_unit': 'cars'},\n",
       " {'question': 'How many data centers did AWS begin using recycled water for cooling in 2023?',\n",
       "  'answer_unit': 'data centers'},\n",
       " {'question': \"Since NVIDIA doesn't release the embodied carbon emissions of its hardware, what are the estimated embodied carbon emissions in kg per GPU?\",\n",
       "  'answer_unit': 'kg/GPU'},\n",
       " {'question': 'By what factor was the estimated amortized training cost of GPT-4 greater than the total training budget for FLM-101B?',\n",
       "  'answer_unit': 'ratio'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "test_Q_df = pd.read_csv(\"test_Q.csv\")\n",
    "test_Q_ids = test_Q_df[\"id\"].tolist()\n",
    "test_Q_df = test_Q_df[[\"question\", \"answer_unit\"]]\n",
    "test_Q = test_Q_df.to_dict(orient=\"records\")\n",
    "test_Q[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7e211ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在初始化模型 'all-MiniLM-L6-v2'...\n",
      "模型初始化完成。\n",
      "正在初始化名詞搜尋引擎...\n",
      "正在從 './corpus_text_only.json' 建立索引...\n",
      "索引建立完成。共處理 32 個文件，發現 15577 個獨特名詞。\n",
      "引擎初始化完成。\n",
      "從 ./corpus_text_only.json 載入並過濾文件...\n",
      "成功載入 4817 個不重複的文件片段。\n",
      "正在將文件編碼為向量...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 151/151 [00:01<00:00, 83.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "建立 FAISS 索引...\n",
      "索引建立完成，共包含 4817 個向量。\n",
      "\n",
      "執行名詞搜尋: \"In a typical datacenter, GPUs account for what percentage of the total provisioned power?\"\n",
      "查詢中的名詞: {'datacenter', 'total', 'percentage', 'account', 'gpus', 'power'}\n",
      "查詢 216/282: 找到 388 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"The training infrastructure for JetMoE-8B consisted of a cluster of 12 nodes. How many total H100 GPUs were used for the training?\"\n",
      "查詢中的名詞: {'cluster', 'training', 'nodes', 'h100', 'jetmoe-8b', 'infrastructure', 'gpus'}\n",
      "查詢 217/282: 找到 247 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"During the first 300 logging steps of OLMo 2 7B training, what is the average GPU power for a single node while actively training?\"\n",
      "查詢中的名詞: {'steps', 'training', 'gpu', 'power', 'olmo', 'node'}\n",
      "查詢 218/282: 找到 291 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"How many pounds of CO2e are estimated for an average human life in one year (globally)?\"\n",
      "查詢中的名詞: {'year', 'life', 'co2e', 'pounds'}\n",
      "查詢 219/282: 找到 290 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What was the approximate speedup in inference throughput for LLaMA-13B when using NVIDIA A100 GPUs compared to V100 GPUs?\"\n",
      "查詢中的名詞: {'nvidia', 'llama-13b', 'inference', 'v100', 'gpus', 'throughput', 'speedup', 'a100'}\n",
      "查詢 220/282: 找到 387 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What is the energy consumption (in Wh) of a single short query to GPT-4o?\"\n",
      "查詢中的名詞: {'energy', 'query', 'gpt-4o', 'consumption', 'wh'}\n",
      "查詢 221/282: 找到 343 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"In the online workload experiment with a 400 TPS SLO, by approximately what percentage was the Max-Performance instance (g6e.xlarge) more expensive than InferSave's top choice?\"\n",
      "查詢中的名詞: {'online', 'percentage', 'g6e.xlarge', 'instance', 'workload', 'slo', 'experiment', 'infersave', 'choice', 'tps'}\n",
      "查詢 222/282: 找到 342 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"Which GPU architecture was most energy-efficient for models generating only a single classification token?\"\n",
      "查詢中的名詞: {'token', 'architecture', 'classification', 'models', 'gpu'}\n",
      "查詢 223/282: 找到 335 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"True or False: Green AI involves providing the financial cost of finding, training, and running models.\"\n",
      "查詢中的名詞: {'cost', 'true', 'training', 'ai', 'models'}\n",
      "查詢 224/282: 找到 209 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"As stated in a 2025 paper, what was the total amount of electronic waste generated worldwide in the year 2022?\"\n",
      "查詢中的名詞: {'amount', 'waste', 'paper', 'year', 'worldwide'}\n",
      "查詢 225/282: 找到 494 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"(Multi-step Question) What is the difference in average system power per processor between the TPU v2 and the V100 GPU?\"\n",
      "查詢中的名詞: {'tpu', 'multi-step', 'processor', 'system', 'v2', 'question', 'difference', 'v100', 'gpu', 'power'}\n",
      "查詢 226/282: 找到 259 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"How much clean freshwater can training the GPT-3 language model in Microsoft's U.S. data centers directly evaporate?\"\n",
      "查詢中的名詞: {'microsoft', 'data', 'freshwater', 'centers', 'gpt-3', 'u.s.', 'language', 'model'}\n",
      "查詢 227/282: 找到 314 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"How much did Facebook's recommendation and ranking model sizes increase between 2019 and 2021?\"\n",
      "查詢中的名詞: {'facebook', 'model', 'increase', 'recommendation'}\n",
      "查詢 228/282: 找到 126 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"Which model ranked highest in a recent eco-efficiency analysis using DEA?\"\n",
      "查詢中的名詞: {'model', 'eco-efficiency', 'dea', 'analysis'}\n",
      "查詢 229/282: 找到 235 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"True or False: Smartphones currently average lifetimes of less than 3 years, contributing to e-waste concerns.\"\n",
      "查詢中的名詞: {'true', 'smartphones', 'years', 'lifetimes', 'e-waste', 'concerns'}\n",
      "查詢 230/282: 找到 173 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"True or False: Intra-zone scaling with T4 GPUs achieved nearly linear per-GPU speedup for CV models.\"\n",
      "查詢中的名詞: {'true', 'cv', 't4', 'models', 'gpus', 'speedup', 'scaling'}\n",
      "查詢 231/282: 找到 369 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What is the context window size, in tokens, for the FLM-101B model?\"\n",
      "查詢中的名詞: {'window', 'flm-101b', 'size', 'model', 'tokens', 'context'}\n",
      "查詢 232/282: 找到 80 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"True or False: LLMs generally have lower power draw during inference than diffusion models because LLM decoding is less compute-intensive and bottlenecked by VRAM bandwidth.\"\n",
      "查詢中的名詞: {'bandwidth', 'true', 'vram', 'inference', 'draw', 'llms', 'decoding', 'models', 'diffusion', 'llm', 'power'}\n",
      "查詢 233/282: 找到 288 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"In 2023, what percentage of Amazon's People Managers globally identified as women?\"\n",
      "查詢中的名詞: {'managers', 'women', 'percentage', 'people', 'amazon'}\n",
      "查詢 234/282: 找到 414 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"When excluding equity, what was the percentage range of total amortized cost attributed to computing hardware for the four key models analyzed by Cottier et al. (2025)?\"\n",
      "查詢中的名詞: {'cost', 'hardware', 'key', 'percentage', 'cottier', 'equity', 'al', 'models', 'range'}\n",
      "查詢 235/282: 找到 337 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"True or False: In the financial sentiment case study, accuracy and F1 scores always improved after optimization.\"\n",
      "查詢中的名詞: {'optimization', 'true', 'sentiment', 'case', 'study', 'scores', 'accuracy', 'f1'}\n",
      "查詢 236/282: 找到 77 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What is the average CO2 produced, in pounds per kilowatt-hour (lbs/kWh), for power consumed in the U.S., as provided by the U.S. Environmental Protection Agency (EPA)?\"\n",
      "查詢中的名詞: {'environmental', 'lbs/kwh', 'epa', 'protection', 'agency', 'kilowatt-hour', 'u.s.', 'co2', 'power', 'pounds'}\n",
      "查詢 237/282: 找到 492 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"According to one study, what is the projected range of electricity consumption by the global AI in 2027?\"\n",
      "查詢中的名詞: {'study', 'electricity', 'consumption', 'ai', 'range'}\n",
      "查詢 238/282: 找到 270 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"How many packages, in millions, did Amazon deliver via EVs in Europe in 2023?\"\n",
      "查詢中的名詞: {'millions', 'evs', 'packages', 'europe', 'amazon'}\n",
      "查詢 239/282: 找到 369 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What was the total number of tokens (input + output) processed during the entire online inference workload evaluation?\"\n",
      "查詢中的名詞: {'online', 'inference', 'workload', 'output', 'evaluation', 'tokens', 'number'}\n",
      "查詢 240/282: 找到 390 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"True or False: The AI Act mandates providers to disclose the greenhouse gas emissions of AI applications, such as oil and gas exploration.\"\n",
      "查詢中的名詞: {'true', 'gas', 'providers', 'act', 'oil', 'exploration', 'applications', 'ai', 'greenhouse', 'emissions'}\n",
      "查詢 241/282: 找到 486 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"According to the 'Flexible Start' optimization analysis in the 2022 Dodge et al. paper, what is the maximum potential percentage reduction in CO2 emissions for a short job (DenseNet 201) in the West US region?\"\n",
      "查詢中的名詞: {'region', 'start', 'optimization', 'dodge', 'paper', 'percentage', 'reduction', 'job', 'analysis', 'densenet', 'us', 'co2', 'al', 'emissions', 'west'}\n",
      "查詢 242/282: 找到 478 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"Based on findings from a 2024 study, by what factor does the energy required for the most intensive task (image generation) exceed that of the least intensive task (text classification)?\"\n",
      "查詢中的名詞: {'image', 'energy', 'generation', 'findings', 'study', 'classification', 'factor', 'task'}\n",
      "查詢 243/282: 找到 274 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"True or False: In Yelp sentiment analysis benchmarks, traditional models achieved accuracy comparable to large language models.\"\n",
      "查詢中的名詞: {'true', 'sentiment', 'analysis', 'benchmarks', 'yelp', 'language', 'models'}\n",
      "查詢 244/282: 找到 231 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"As of January 2024, how many Amazon Renewable Energy Projects were announced in the United States?\"\n",
      "查詢中的名詞: {'energy', 'january', 'renewable', 'projects', 'united', 'states', 'amazon'}\n",
      "查詢 245/282: 找到 579 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What percent of power usage did Amazon's AWS cover with renewable energy in 2018?\"\n",
      "查詢中的名詞: {'aws', 'energy', 'cover', 'usage', 'percent', 'power', 'amazon'}\n",
      "查詢 246/282: 找到 440 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"At which measurement level do the authors recommend AI energy consumption should be reported to balance accuracy and feasibility?\"\n",
      "查詢中的名詞: {'measurement', 'energy', 'level', 'authors', 'consumption', 'ai', 'feasibility', 'accuracy'}\n",
      "查詢 247/282: 找到 320 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"In an experiment to train a BERT-base model, what percentage of the total electricity consumption was attributed to the GPU?\"\n",
      "查詢中的名詞: {'bert-base', 'electricity', 'percentage', 'consumption', 'experiment', 'model', 'gpu'}\n",
      "查詢 248/282: 找到 364 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"Serving a Llama2-70b model at BF16 precision requires how many NVIDIA A100-80GB GPUs?\"\n",
      "查詢中的名詞: {'nvidia', 'precision', 'gpus', 'bf16', 'model', 'a100-80gb'}\n",
      "查詢 249/282: 找到 227 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What was the total operational energy footprint reduction achieved at Facebook over a two-year period (2019 to 2021) due to iterative hardware-software optimization?\"\n",
      "查詢中的名詞: {'facebook', 'energy', 'optimization', 'reduction', 'footprint', 'period'}\n",
      "查詢 250/282: 找到 384 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"How many kilometers of fiber optic cable were installed globally to support AI workloads in 2023?\"\n",
      "查詢中的名詞: {'cable', 'fiber', 'workloads', 'kilometers', 'ai'}\n",
      "查詢 251/282: 找到 289 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What is the estimated upfront hardware acquisition cost to train GPT-4?\"\n",
      "查詢中的名詞: {'cost', 'acquisition', 'hardware', 'gpt-4'}\n",
      "查詢 252/282: 找到 240 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"True or False: The umbrella term 'Sustainable AI' was proposed to only encompass using AI in climate-positive applications.\"\n",
      "查詢中的名詞: {'ai', 'term', 'true', 'applications'}\n",
      "查詢 253/282: 找到 438 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What is the ground truth maximum batch size (in samples) for fine-tuning a Mixtral model on a NVIDIA A100-40GB GPU\"\n",
      "查詢中的名詞: {'mixtral', 'nvidia', 'batch', 'samples', 'a100-40gb', 'truth', 'size', 'model', 'ground', 'gpu'}\n",
      "查詢 254/282: 找到 251 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"When an LLM inference server is overloaded, which of the two preemption mechanisms-Recomputation or Swapping-consistently consumes less energy?\"\n",
      "查詢中的名詞: {'energy', 'mechanisms-recomputation', 'preemption', 'inference', 'consumes', 'server', 'llm'}\n",
      "查詢 255/282: 找到 244 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"In its 2024 environmental report, what percentage increase in GHG emissions since 2019 did Google report?\"\n",
      "查詢中的名詞: {'increase', 'percentage', 'report', 'ghg', 'emissions', 'google'}\n",
      "查詢 256/282: 找到 471 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"According to McKinsey projections, what percentage of U.S. national electricity consumption are data centers anticipated to account for in 2030?\"\n",
      "查詢中的名詞: {'mckinsey', 'electricity', 'percentage', 'projections', 'centers', 'consumption', 'u.s.'}\n",
      "查詢 257/282: 找到 454 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"When using the 'Pause and Resume' optimization for training of the 6B parameter transformer, what is the maximum potential emissions saving?\"\n",
      "查詢中的名詞: {'optimization', 'training', \"'pause\", 'transformer', 'parameter', 'emissions', 'resume'}\n",
      "查詢 258/282: 找到 190 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"By approximately what percentage does the JetMoE-8B architecture reduce inference computation compared to the Llama2-7B model?\"\n",
      "查詢中的名詞: {'inference', 'architecture', 'percentage', 'model', 'llama2-7b', 'computation'}\n",
      "查詢 259/282: 找到 266 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What was the carbon footprint (in lbs CO2e) of training the BERT large language model, as quantified in a seminal 2019 study?\"\n",
      "查詢中的名詞: {'model', 'study', 'carbon', 'co2e', 'lbs', 'language', 'bert', 'footprint'}\n",
      "查詢 260/282: 找到 309 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What was the estimated training energy of the full GPT-3 model, in MWh?\"\n",
      "查詢中的名詞: {'energy', 'training', 'mwh', 'gpt-3', 'model'}\n",
      "查詢 261/282: 找到 306 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"True or False: When enhancing performance of LLM fine-tuning, the Mixture of Experts (MoE) layer is often a targeted layer.\"\n",
      "查詢中的名詞: {'true', 'fine-tuning', 'moe', 'performance', 'mixture', 'experts', 'layer', 'llm'}\n",
      "查詢 262/282: 找到 315 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What is the maximum batch size (in samples) supported by fine-tuning Mixtral with a dense setup on the Hellaswag dataset using a NVIDIA A40 GPU with 48 GB memory?\"\n",
      "查詢中的名詞: {'mixtral', 'nvidia', 'batch', 'samples', 'dataset', 'gb', 'memory', 'a40', 'hellaswag', 'size', 'gpu', 'setup'}\n",
      "查詢 263/282: 找到 338 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"True or False: For CV models with high granularity, intercontinental training slowed performance by only 7% compared to local training.\"\n",
      "查詢中的名詞: {'granularity', 'true', 'training', 'performance', 'cv', 'models'}\n",
      "查詢 264/282: 找到 110 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"How many hectares of land were occupied by new AI data centers globally in 2022?\"\n",
      "查詢中的名詞: {'hectares', 'land', 'data', 'centers', 'ai'}\n",
      "查詢 265/282: 找到 382 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"A 2024 study compares task-specific and general-purpose models. How many grams of CO2eq are emitted by the BERT-based model bert-base-multilingual-uncased-sentiment per 1,000 text classification queries?\"\n",
      "查詢中的名詞: {'queries', 'study', 'grams', 'classification', 'model', 'models', 'co2eq'}\n",
      "查詢 266/282: 找到 298 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"In the experiment analyzing emissions from training a BERT model across different geographic regions, what was the approximate range of CO2 emissions (in thousands of grams) between the most and least efficient regions?\"\n",
      "查詢中的名詞: {'model', 'thousands', 'co2', 'experiment', 'bert', 'grams', 'range', 'emissions', 'regions'}\n",
      "查詢 267/282: 找到 460 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"In what year did the practice of directly releasing environmental information for notable models peak before declining?\"\n",
      "查詢中的名詞: {'models', 'year', 'information', 'practice'}\n",
      "查詢 268/282: 找到 341 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What is the equivalent water usage, in days, for one person in the US, of training an OLMo 60M model on 1.7 to 5.6 trillion tokens?\"\n",
      "查詢中的名詞: {'person', 'water', 'days', 'us', 'usage', 'model', 'tokens', 'olmo'}\n",
      "查詢 269/282: 找到 352 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"How many liters of freshwater did Google's DeepMind AlphaFold servers consume in 2023?\"\n",
      "查詢中的名詞: {'alphafold', 'freshwater', 'deepmind', 'liters', 'servers', 'google'}\n",
      "查詢 270/282: 找到 399 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"True or False: Adding compute resources to accelerate the MoE layers when fine-tuning LLMs can increase costs.\"\n",
      "查詢中的名詞: {'true', 'moe', 'llms', 'costs', 'compute', 'resources', 'adding', 'layers'}\n",
      "查詢 271/282: 找到 333 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"According to a carbon footprint analysis, what was the total energy consumption for training the FLM-101B model?\"\n",
      "查詢中的名詞: {'energy', 'analysis', 'consumption', 'carbon', 'flm-101b', 'model', 'footprint'}\n",
      "查詢 272/282: 找到 329 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"According to a recent study's projections for 2030, the total public health burden of U.S. data centers could be valued at up to more than what amount?\"\n",
      "查詢中的名詞: {'amount', 'study', 'data', 'projections', 'centers', 'u.s.', 'burden', 'health'}\n",
      "查詢 273/282: 找到 548 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What is the estimated total cost of fine-tuning a Mixtral model on the GSM8K dataset with sparse MoE with an NVIDIA A40-48GB GPU?\"\n",
      "查詢中的名詞: {'cost', 'mixtral', 'nvidia', 'moe', 'model', 'a40-48gb', 'dataset', 'gsm8k', 'gpu'}\n",
      "查詢 274/282: 找到 324 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"For a sparse Mixtral model fine-tuned with a NVIDIA A40-48 GB, what was the batch size (in samples) of the longest-running MoE layer?\"\n",
      "查詢中的名詞: {'mixtral', 'nvidia', 'moe', 'batch', 'samples', 'gb', 'size', 'model', 'layer', 'a40-48'}\n",
      "查詢 275/282: 找到 244 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What is the total execution time, in seconds, of a sparse Mixtral model fine-tuned with a NVIDIA A40-48GB with a batch size of 10?\"\n",
      "查詢中的名詞: {'mixtral', 'nvidia', 'batch', 'a40-48gb', 'time', 'size', 'model', 'execution', 'seconds'}\n",
      "查詢 276/282: 找到 365 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"True or False: GPU-level power consumption monitoring is recommended as the preferred method for reporting overall AI energy use.\"\n",
      "查詢中的名詞: {'energy', 'true', 'method', 'monitoring', 'use', 'consumption', 'ai', 'power'}\n",
      "查詢 277/282: 找到 314 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"In a 2023 article estimating the carbon footprint of the BLOOM model, what percentage of the model's overall emissions did training account for?\"\n",
      "查詢中的名詞: {'percentage', 'article', 'carbon', 'account', 'bloom', 'model', 'footprint', 'emissions'}\n",
      "查詢 278/282: 找到 461 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What is the bare minimum number of NVIDIA V100 32GB GPUs required to run LLaMA-7B inference without compression or quantization?\"\n",
      "查詢中的名詞: {'nvidia', 'quantization', 'inference', 'llama-7b', 'bare', 'compression', 'v100', 'gpus', 'number'}\n",
      "查詢 279/282: 找到 281 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"When training GPT-3 in a data center in Arizona, how many user requests would it take to consume a 500ml bottle of water?\"\n",
      "查詢中的名詞: {'center', 'arizona', 'user', 'data', 'water', 'gpt-3', 'requests', 'bottle'}\n",
      "查詢 280/282: 找到 224 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"What is the estimated CO2 emission in metric tons for one year of average US home energy use?\"\n",
      "查詢中的名詞: {'energy', 'home', 'us', 'year', 'co2', 'emission', 'tons', 'use'}\n",
      "查詢 281/282: 找到 475 個相關結果。\n",
      "\n",
      "執行名詞搜尋: \"On the GSM8k benchmark, which evaluates grade school math problem-solving, what score did the JetMoE-8B model achieve?\"\n",
      "查詢中的名詞: {'achieve', 'model', 'school', 'math', 'problem-solving', 'jetmoe-8b', 'benchmark', 'gsm8k'}\n",
      "查詢 282/282: 找到 195 個相關結果。\n"
     ]
    }
   ],
   "source": [
    "from rag_retrieve import VectorSearchEngine\n",
    "from noun_search import NounSearchEngine\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "def main():\n",
    "    \"\"\"主執行函數，展示如何使用 VectorSearchEngine 類別。\"\"\"\n",
    "    json_file_path = \"./corpus_text_only.json\"\n",
    "    if not os.path.exists(json_file_path):\n",
    "        print(f\"錯誤: 找不到檔案 '{json_file_path}'\")\n",
    "        return\n",
    "\n",
    "    # 1. 建立引擎實例\n",
    "    engine = VectorSearchEngine()\n",
    "    noun_engine = NounSearchEngine(json_file_path)\n",
    "\n",
    "    # 2. 從 JSON 檔案建立初始索引\n",
    "    engine.build_from_json(json_file_path)\n",
    "\n",
    "    if os.path.exists(\"generated_answers.csv\"):\n",
    "        output_df = pd.read_csv(\"generated_answers.csv\")\n",
    "    else:\n",
    "        output_df = pd.DataFrame(columns=[\"id\", \"answer\", \"answer_value\", \"answer_unit\", \"supporting_materials\", \"explanation\", \"ref_id\", \"ref_url\"])\n",
    "\n",
    "    output_df = output_df.astype({'id': str, 'answer': str, 'answer_value': str, 'answer_unit': str, 'supporting_materials': str, 'explanation': str, 'ref_id': object, 'ref_url': object})\n",
    "\n",
    "    # for i in range(3):  # 只執行一次查詢示範\n",
    "    for i in range(len(output_df), len(test_Q)):  # 執行所有測試查詢\n",
    "        # 3. 執行查詢\n",
    "        query = test_Q[i]\n",
    "        emb_search_results = engine.get(query['question'], k=800)\n",
    "        noun_search_results = noun_engine.search(query['question'], top_k=10)\n",
    "        emb_search_results = [res for res in emb_search_results if res['score'] < 1.5]  # 過濾掉距離過大的結果\n",
    "        noun_search_results = [res for res in noun_search_results if res['score'] >= 1]  # 保留匹配到至少一個名詞的結果\n",
    "        # 合併兩種搜尋結果\n",
    "        search_results = []\n",
    "        for sr in emb_search_results:\n",
    "            if sr['id'] in [r['id'] for r in noun_search_results]:\n",
    "                search_results.append(sr)\n",
    "        \n",
    "\n",
    "\n",
    "        if len(search_results) == 0:\n",
    "            max_index_result = engine.get(query['question'], k=10)\n",
    "            search_results = max_index_result\n",
    "        print(f\"查詢 {i+1}/{len(test_Q)}: 找到 {len(search_results)} 個相關結果。\")\n",
    "\n",
    "        # print(\"\\n--- 搜尋結果 ---\")\n",
    "        # if not search_results:\n",
    "        #     print(\"找不到相關結果。\")\n",
    "        # else:\n",
    "        #     for i, result in enumerate(search_results):\n",
    "        #         print(f\"\\n結果 {i+1}:\")\n",
    "        #         print(f\"  - ID: {result['id']}\")\n",
    "        #         print(f\"  - 相似度分數 (L2 距離): {result['score']:.4f}\")\n",
    "        #         print(f\"  - 相關文本: \\\"{result['text']}\\\"\")\n",
    "\n",
    "\n",
    "        prompt = f\"These are the example QAs: {example_outputs}. Based on the retrieved documents, {search_results}, answer the question: {query}. answer in json format\"\n",
    "\n",
    "        json_schema = Schema(\n",
    "            type=Type.OBJECT,\n",
    "            properties={\n",
    "                \"id\": Schema(type=Type.STRING),\n",
    "                \"answer\": Schema(type=Type.STRING),\n",
    "                \"answer_value\": Schema(type=Type.STRING),\n",
    "                \"answer_unit\": Schema(type=Type.STRING),\n",
    "                \"supporting_materials\": Schema(type=Type.STRING),\n",
    "                \"explanation\": Schema(type=Type.STRING),\n",
    "                # 註: ref_id 和 ref_url 不需在 schema 中，因為它們是在 Python 中後續添加的\n",
    "            }\n",
    "        )\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=prompt,\n",
    "            config=GenerateContentConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=json_schema,\n",
    "            )\n",
    "        )\n",
    "        json_string = response.text.removeprefix(\"```json\").removesuffix(\"```\").strip()\n",
    "        #remove wierd characters\n",
    "        json_string = ''.join(c for c in json_string if c.isprintable())\n",
    "        output_dict = json.loads(json_string)\n",
    "        output_dict['id'] = test_Q_ids[i]\n",
    "        output_dict['ref_id'] = []\n",
    "        search_results.sort(key=lambda x: x['score'])\n",
    "        output_dict['ref_id'] = list(set([res['id'] for res in search_results[:3]]))\n",
    "        output_dict['ref_url'] = list(set([res['url'] for res in search_results[:3]]))\n",
    "\n",
    "        output_df = pd.concat([output_df, pd.DataFrame([output_dict])], ignore_index=True)\n",
    "\n",
    "        # print(\"\\n--- 生成的回答 ---\")\n",
    "\n",
    "        # print(output_dict)\n",
    "        output_df.to_csv(\"generated_answers.csv\", index=False)\n",
    "        time.sleep(10)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7d9ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63659/1682893301.py:3: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  output_df['supporting_materials'][index] = row['supporting_materials'].replace('\\n', ' ').replace('\"', \"'\")\n"
     ]
    }
   ],
   "source": [
    "output_df = pd.read_csv(\"generated_answers.csv\")\n",
    "for index, row in output_df.iterrows():\n",
    "    output_df['supporting_materials'][index] = row['supporting_materials'].replace('\\n', ' ').replace('\"', \"'\")\n",
    "output_df.to_csv(\"final_answers.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
